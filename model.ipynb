{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, num_heads=4, hidden_dim=256, num_layers=4, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        # Transformer Encoder Layers\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=hidden_dim, \n",
    "            dropout=dropout, \n",
    "            batch_first=True  # Ensures (batch, seq_len, feature_dim) ordering\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Pooling layer to get a fixed-size customer embedding\n",
    "        self.pooling_layer = nn.AdaptiveAvgPool1d(1)  # Mean pooling\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, 128) -> Transaction sequences\n",
    "        mask: (batch_size, seq_len) -> Padding mask (1 for real, 0 for padding)\n",
    "        \"\"\"\n",
    "        # Convert mask: Transformer expects \"True\" for positions to ignore\n",
    "        if mask is not None:\n",
    "            mask = mask == 0  # Now 1->False (keep), 0->True (ignore)\n",
    "\n",
    "        print(f\"Mask Shape: {mask.shape if mask is not None else None}\")  # Debugging\n",
    "        print(f\"Input Shape: {x.shape}\")  # Debugging\n",
    "\n",
    "        # Transformer encoder processes the sequence\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=mask)\n",
    "\n",
    "        # Mean Pooling: Convert (batch_size, seq_len, 128) -> (batch_size, 128)\n",
    "        x = x.permute(0, 2, 1)  # Change shape for pooling\n",
    "        x = self.pooling_layer(x)  # Shape: (batch, 128, 1)\n",
    "        x = x.squeeze(-1)  # Shape: (batch, 128)\n",
    "\n",
    "        return x  # Customer embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "max_seq_len = 10  # Assume max transactions per batch is 10\n",
    "input_dim = 128\n",
    "\n",
    "# Simulated batch of customer transaction sequences (padded where needed)\n",
    "x = torch.randn(batch_size, max_seq_len, input_dim)\n",
    "\n",
    "# Simulated mask (1 for real transactions, 0 for padding)\n",
    "mask = torch.tensor([\n",
    "    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],  # Customer 1: 5 transactions\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # Customer 2: 10 transactions\n",
    "    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]   # Customer 3: 7 transactions\n",
    "])\n",
    "\n",
    "model = TransformerEncoder()\n",
    "output_embeddings = model(x, mask)\n",
    "\n",
    "print(\"Final Customer Embeddings Shape:\", output_embeddings.shape)  # (batch_size, 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
