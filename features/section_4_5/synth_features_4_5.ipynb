{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures\n",
    "import pickle as pkl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open('../../processed_synth_dataset/synth_features_4_5.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = pd.concat([value for key, value in data], axis = 1, join='outer')\n",
    "# for key, value in data:\n",
    "#     print(key)\n",
    "#     print(value.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wire Transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 1\n",
    "wire = pd.read_csv('../../processed_synth_dataset/wire_s.csv', engine=\"pyarrow\").sample(frac = frac)\n",
    "ach = pd.read_csv('../../processed_synth_dataset/ach_s.csv', engine=\"pyarrow\").sample(frac = frac)\n",
    "cheque = pd.read_csv('../../processed_synth_dataset/cheque_s.csv', engine=\"pyarrow\").sample(frac = frac)\n",
    "card = pd.read_csv('../../processed_synth_dataset/card_s.csv', engine=\"pyarrow\").sample(frac = frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5308695\n"
     ]
    }
   ],
   "source": [
    "print(len(wire)+len(ach)+len(cheque)+len(card)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Wire transactions:  228567\n",
      "# of ABM transactions:  796581\n",
      "# of Cheque transactions:  2503158\n",
      "# of Card transactions:  1780389\n"
     ]
    }
   ],
   "source": [
    "print(\"# of Wire transactions: \", wire.shape[0])\n",
    "print(\"# of ABM transactions: \", ach.shape[0])\n",
    "print(\"# of Cheque transactions: \", cheque.shape[0])\n",
    "print(\"# of Card transactions: \", card.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = {'card': card, 'wire': wire, 'ach': ach, 'cheque': cheque}\n",
    "dfs = {'wire': wire}\n",
    "#Sorting the DFs by date and Time\n",
    "for key in dfs.keys():\n",
    "    dfs[key]['transaction_datetime'] = pd.to_datetime(dfs[key]['transaction_date'].astype(str) + ' ' + dfs[key]['transaction_time'].astype(str))\n",
    "    dfs[key].sort_values( by = ['customer_id', 'transaction_datetime'] , ascending = [True, True], ignore_index=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to divide the date range into weekly and monthly ranges\n",
    "def get_date_ranges(start_date, end_date):\n",
    "    # Convert the start and end date to datetime\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    start_date_week = start_date\n",
    "    end_date_week = end_date\n",
    "    \n",
    "    start_date_month = start_date\n",
    "    end_date_month = end_date\n",
    "    \n",
    "    # Adjust the start_date to the previous Monday if it's not already a Monday\n",
    "    if start_date_week.weekday() != 0:\n",
    "        start_date_week -= pd.Timedelta(days=start_date_week.weekday())\n",
    "    \n",
    "    # Adjust the end_date to the next Sunday if it's not already a Sunday\n",
    "    if end_date_week.weekday() != 6:\n",
    "        end_date_week += pd.Timedelta(days=(6 - end_date_week.weekday()))\n",
    "    \n",
    "    # Generate a range of dates from start_date to end_date with a frequency of 'W-MON' (weekly on Monday)\n",
    "    week_starts = pd.date_range(start=start_date_week, end=end_date_week, freq='W-MON')\n",
    "    \n",
    "    # Create a list of tuples with start and end dates for each week\n",
    "    weekly_ranges = []\n",
    "    for start in week_starts:\n",
    "        end = start + pd.Timedelta(days=6)\n",
    "        weekly_ranges.append((start, end))\n",
    "    \n",
    "    # Adjust the start_date to the first day of the month\n",
    "    start_date_month = start_date_month.replace(day=1)\n",
    "    \n",
    "    # Adjust the end_date to the last day of the month\n",
    "    if end_date_month.days_in_month != end_date_month.day:\n",
    "        end_date_month.replace(day=end_date_month.days_in_month)\n",
    "        \n",
    "    # end_date_month = (end_date_month + pd.offsets.MonthEnd(1)).normalize()\n",
    "    \n",
    "    # Generate a range of dates from start_date_month to end_date_month with a frequency of 'MS' (monthly start)\n",
    "    month_starts = pd.date_range(start=start_date_month, end=end_date_month, freq='MS')\n",
    "    \n",
    "    # Create a list of tuples with start and end dates for each month\n",
    "    monthly_ranges = []\n",
    "    for start in month_starts:\n",
    "        end = (start + pd.offsets.MonthEnd(1)).normalize()\n",
    "        monthly_ranges.append((start, end))\n",
    "    \n",
    "    return weekly_ranges, monthly_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minute_day_ranges(start_date_time, end_date_time):\n",
    "    # Convert inputs to pandas timestamps\n",
    "    start_date_time = pd.to_datetime(start_date_time)\n",
    "    end_date_time = pd.to_datetime(end_date_time)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # 60-minute intervals\n",
    "    # ------------------------------------------\n",
    "    # Align the start to the nearest 60-minute boundary (rounding down)\n",
    "    start_60min = start_date_time.floor('60min')\n",
    "    # Align the end to the nearest 60-minute boundary (rounding up)\n",
    "    end_60min = end_date_time.ceil('60min')\n",
    "\n",
    "    # Create 60-minute interval ranges.\n",
    "    # We subtract 60 minutes from end_5min because we want full 60-minute blocks.\n",
    "    five_min_intervals = []\n",
    "    five_min_starts = pd.date_range(start=start_60min, \n",
    "                                    end=end_60min - pd.Timedelta(minutes=5), \n",
    "                                    freq='60min')\n",
    "    for start in five_min_starts:\n",
    "        # Define the end of the interval as exactly 5 minutes later,\n",
    "        # subtracting a microsecond so that intervals don't overlap (if needed)\n",
    "        end = start + pd.Timedelta(minutes=60) - pd.Timedelta(microseconds=1)\n",
    "        five_min_intervals.append((start, end))\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Daily intervals\n",
    "    # ------------------------------------------\n",
    "    # Normalize the start to midnight\n",
    "    start_day = start_date_time.normalize()\n",
    "    # Normalize the end to midnight.\n",
    "    # Note: if end_date_time is not exactly midnight, this represents the beginning\n",
    "    #       of that day. That day will be included as a full day interval.\n",
    "    end_day = end_date_time.normalize()\n",
    "\n",
    "    daily_intervals = []\n",
    "    # Create a date_range for each day\n",
    "    day_starts = pd.date_range(start=start_day, end=end_day, freq='D')\n",
    "    for day in day_starts:\n",
    "        # Each interval spans the entire day.\n",
    "        # We set the end to be one day later minus one microsecond.\n",
    "        day_end = day + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)\n",
    "        daily_intervals.append((day, day_end))\n",
    "\n",
    "    return five_min_intervals, daily_intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Minute Intervals:\n",
      "(Timestamp('2025-01-01 12:00:00'), Timestamp('2025-01-01 12:59:59.999999'))\n",
      "(Timestamp('2025-01-01 13:00:00'), Timestamp('2025-01-01 13:59:59.999999'))\n",
      "\n",
      "Daily Intervals:\n",
      "(Timestamp('2025-01-01 00:00:00'), Timestamp('2025-01-01 23:59:59.999999'))\n"
     ]
    }
   ],
   "source": [
    "start = pd.Timestamp(\"2025-01-01 12:03:15\")\n",
    "end = pd.Timestamp(\"2025-01-01 13:02:45\")\n",
    "five_min_ranges, daily_ranges = get_minute_day_ranges(start, end)\n",
    "print(\"5-Minute Intervals:\")\n",
    "for interval in five_min_ranges:\n",
    "    print(interval)\n",
    "print(\"\\nDaily Intervals:\")\n",
    "for interval in daily_ranges:\n",
    "    print(interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Collecting all unique customer IDs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m wire_customers \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwire\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m----> 4\u001b[0m ach_customers \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      5\u001b[0m cheque_customers \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheque\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      6\u001b[0m card_customers \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcard\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ach'"
     ]
    }
   ],
   "source": [
    "#Collecting all unique customer IDs\n",
    "\n",
    "wire_customers = dfs['wire']['customer_id'].unique()\n",
    "ach_customers = dfs['ach']['customer_id'].unique()\n",
    "cheque_customers = dfs['cheque']['customer_id'].unique()\n",
    "card_customers = dfs['card']['customer_id'].unique()\n",
    "\n",
    "all_customers= list(set(np.concatenate((wire_customers, ach_customers, cheque_customers, card_customers), axis=0)))\n",
    "print(len(all_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# import random\\n# from datetime import datetime, timedelta\\n\\n# # Define a two-day time window\\n# start_date = datetime(2023, 1, 1)\\n# end_date = datetime(2023, 1, 2, 23, 59, 59)\\n\\n# def random_date(start, end):\\n#     \"\"\"Return a random datetime between start and end.\"\"\"\\n#     delta = end - start\\n#     random_seconds = random.randint(0, int(delta.total_seconds()))\\n#     return start + timedelta(seconds=random_seconds)\\n\\n# # Create a list of 20 unique customers (alphanumeric IDs)\\n\\n# customer_ids = [f\"C{str(i).zfill(3)}\" for i in random.choices(range(1, 3), k=20)]\\n\\n# # Prepare a list to hold each transaction as a dictionary\\n# data = []\\n\\n# # Generate 20 transactions (one per customer)\\n# for cid in customer_ids:\\n#     txn = {\\n#         \\'customer_id\\': cid,\\n#         \\'debit_credit\\': random.choice([\\'debit\\', \\'credit\\']),\\n#         \\'amount_cad\\': random.randint(10, 50),\\n#         \\'transaction_datetime\\': random_date(start_date, end_date)\\n#     }\\n#     data.append(txn)\\n\\n# # Enforce that two transactions occur within 5 minutes of each other.\\n# # For example, choose the first two transactions to be within 5 minutes.\\n# base_time = random_date(start_date, end_date)\\n# data[0][\\'transaction_datetime\\'] = base_time\\n# # For the second transaction, add a random delta from 0 to 299 seconds (i.e. less than 5 minutes)\\n# data[1][\\'transaction_datetime\\'] = base_time + timedelta(seconds=random.randint(0, 299))\\n\\n# # Create the DataFrame. The columns are: customer_id, debit_credit, amount_cad, transaction_datetime.\\n# df = pd.DataFrame(data)\\n\\n# df.sort_values(by=[\\'customer_id\\', \\'debit_credit\\',\\'transaction_datetime\\'], ascending=[True, True, True], ignore_index=True, inplace=True)\\n# print(df)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# import random\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # Define a two-day time window\n",
    "# start_date = datetime(2023, 1, 1)\n",
    "# end_date = datetime(2023, 1, 2, 23, 59, 59)\n",
    "\n",
    "# def random_date(start, end):\n",
    "#     \"\"\"Return a random datetime between start and end.\"\"\"\n",
    "#     delta = end - start\n",
    "#     random_seconds = random.randint(0, int(delta.total_seconds()))\n",
    "#     return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "# # Create a list of 20 unique customers (alphanumeric IDs)\n",
    "\n",
    "# customer_ids = [f\"C{str(i).zfill(3)}\" for i in random.choices(range(1, 3), k=20)]\n",
    "\n",
    "# # Prepare a list to hold each transaction as a dictionary\n",
    "# data = []\n",
    "\n",
    "# # Generate 20 transactions (one per customer)\n",
    "# for cid in customer_ids:\n",
    "#     txn = {\n",
    "#         'customer_id': cid,\n",
    "#         'debit_credit': random.choice(['debit', 'credit']),\n",
    "#         'amount_cad': random.randint(10, 50),\n",
    "#         'transaction_datetime': random_date(start_date, end_date)\n",
    "#     }\n",
    "#     data.append(txn)\n",
    "\n",
    "# # Enforce that two transactions occur within 5 minutes of each other.\n",
    "# # For example, choose the first two transactions to be within 5 minutes.\n",
    "# base_time = random_date(start_date, end_date)\n",
    "# data[0]['transaction_datetime'] = base_time\n",
    "# # For the second transaction, add a random delta from 0 to 299 seconds (i.e. less than 5 minutes)\n",
    "# data[1]['transaction_datetime'] = base_time + timedelta(seconds=random.randint(0, 299))\n",
    "\n",
    "# # Create the DataFrame. The columns are: customer_id, debit_credit, amount_cad, transaction_datetime.\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# df.sort_values(by=['customer_id', 'debit_credit','transaction_datetime'], ascending=[True, True, True], ignore_index=True, inplace=True)\n",
    "# print(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with all unique customer IDs to store the features\n",
    "customer_stats = pd.DataFrame(index=sorted(all_customers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10042B660</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042B6A8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042B6F0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042B738</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042B780</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81C1EC560</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81C1EC5B0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81C1EC600</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81C1EC650</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81C1EC6A0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467468 rows Ã— 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [10042B660, 10042B6A8, 10042B6F0, 10042B738, 10042B780, 10042B7C8, 10042B810, 10042B858, 10042B8A0, 10042B8E8, 10042B930, 10042B978, 10042B9C0, 10042BA08, 800043AF0, 800043BE0, 800043DA0, 800044010, 800044060, 800044230, 800044900, 800044DC0, 800044F80, 800045200, 8000457C0, 800045A10, 800045E40, 8000460E0, 8000462A0, 800046660, 800046E90, 800047470, 800047630, 800047860, 800047E30, 800048030, 800048410, 8000485E0, 8000489A0, 8000493D0, 800049520, 8000496E0, 800049A80, 800049B90, 80004A300, 80004A3C0, 80004A5A0, 80004A830, 80004B460, 80004B700, 80004B8B0, 80004BC80, 80004BE90, 80004C790, 80004C910, 80004CAA0, 80004CE40, 80004DA30, 80004DCC0, 80004DE80, 80004E1E0, 80004E7B0, 80004EC10, 80004EE50, 80004EFF0, 80004F320, 80004F660, 80004FBB0, 80004FE40, 800050000, 800050290, 8000508D0, 800050DA0, 800051060, 8000511F0, 800051590, 800051940, 800051E90, 8000520B0, 800052270, 8000525C0, 800052910, 800054100, 800054200, 800054290, 800054460, 800055E30, 800056090, 8000563E0, 800056C90, 800056CE0, 800056ED0, 800057270, 800057660, 800057A30, 800057BB0, 800057E30, 8000581F0, 800058480, 8000586A0, ...]\n",
       "\n",
       "[467468 rows x 0 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 733/64587 [00:48<1:10:34, 15.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/3861982819.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminute_ranges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mperiod_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transaction_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcustomer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transaction_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcredit_period_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'debit_credit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'credit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mdebit_period_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'debit_credit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'debit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredit_period_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_credit_minute_trx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mmax_credit_minute_trx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredit_period_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4074\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4075\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4076\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4081\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4635\u001b[0m             \u001b[0;31m# All places that call _get_item_cache have unique columns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4636\u001b[0m             \u001b[0;31m#  pending resolution of GH#33047\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4639\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4641\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   4007\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4010\u001b[0m             \u001b[0mcol_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4011\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4013\u001b[0m             \u001b[0;31m# this is a cached value, mark it so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4014\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, values, loc)\u001b[0m\n\u001b[1;32m   4612\u001b[0m         \u001b[0;31m# Lookup in columns so that if e.g. a str datetime was passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4613\u001b[0m         \u001b[0;31m#  we attach the Timestamp object as the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4614\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4615\u001b[0m         \u001b[0;31m# We get index=self.index bc values is a SingleDataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4616\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4617\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4618\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, mgr, axes)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constructor_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# caller is responsible for setting real name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;31m# This would also work `if self._constructor_sliced is Series`, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6317\u001b[0m         \u001b[0;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6318\u001b[0m         \u001b[0;31m# (note that this matches __getattr__, above).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_names_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6320\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6322\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for df_key in dfs.keys():\n",
    "    df = dfs[df_key]\n",
    "    df_customers = sorted(df['customer_id'].unique()) \n",
    "    \n",
    "    start_idx = 0\n",
    "    curr_idx = 0\n",
    "    last_idx = None\n",
    "        \n",
    "    for customer in tqdm(df_customers):\n",
    "        end_flag = False\n",
    "        while (df.loc[curr_idx, 'customer_id'] == customer):\n",
    "            # print(df.loc[curr_idx, 'customer_id'])\n",
    "            curr_idx += 1\n",
    "            # print(curr_idx)\n",
    "            if curr_idx == len(df):\n",
    "                end_flag = True\n",
    "                break\n",
    "        last_idx = curr_idx            \n",
    "        \n",
    "        if not end_flag:\n",
    "            customer_df = df.iloc[start_idx:last_idx, :]\n",
    "        else:\n",
    "            customer_df = df.iloc[start_idx:, :]\n",
    "\n",
    "        start_idx = curr_idx\n",
    "        \n",
    "        max_credit_minute_trx = 0 \n",
    "        max_credit_daily_trx = 0\n",
    "        # max_credit_weekly_trx = 0\n",
    "        # max_credit_monthly_trx = 0\n",
    "        max_credit_minute_trx_avg_val = 0\n",
    "        max_credit_daily_trx_avg_val = 0\n",
    "        # max_credit_weekly_trx_avg_val = 0\n",
    "        # max_credit_monthly_trx_avg_val = 0\n",
    "        \n",
    "        max_debit_minute_trx = 0\n",
    "        max_debit_daily_trx = 0\n",
    "        # max_debit_weekly_trx = 0\n",
    "        # max_debit_monthly_trx = 0\n",
    "        max_debit_minute_trx_avg_val = 0\n",
    "        max_debit_daily_trx_avg_val = 0\n",
    "        # max_debit_weekly_trx_avg_val = 0\n",
    "        # max_debit_monthly_trx_avg_val = 0\n",
    "                \n",
    "        start_date = df['transaction_datetime'].min()\n",
    "        end_date = df['transaction_datetime'].max()\n",
    "        # weekly_ranges, monthly_ranges = get_date_ranges(start_date, end_date)\n",
    "        minute_ranges, day_ranges = get_minute_day_ranges(start_date, end_date)\n",
    " \n",
    "        \n",
    "        for i, (start, end) in enumerate(minute_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            if len(credit_period_df) > max_credit_minute_trx:\n",
    "                max_credit_minute_trx = len(credit_period_df)\n",
    "                max_credit_minute_trx_avg_val = credit_period_df['amount_cad'].mean()    \n",
    "            if len(debit_period_df) > max_debit_minute_trx:\n",
    "                max_debit_minute_trx = len(debit_period_df)\n",
    "                max_debit_minute_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "        customer_stats.loc[customer, df_key+'_max_credit_minute_trx'] = max_credit_minute_trx\n",
    "        customer_stats.loc[customer, df_key+'_max_debit_minute_trx_avg_val'] = max_debit_minute_trx_avg_val\n",
    "        customer_stats.loc[customer, df_key+'_max_debit_minute_trx'] = max_debit_minute_trx\n",
    "        customer_stats.loc[customer, df_key+'_max_credit_minute_trx_avg_val'] = max_credit_minute_trx_avg_val\n",
    "        \n",
    "        for i, (start, end) in enumerate(day_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            if len(credit_period_df) > max_credit_daily_trx:\n",
    "                max_credit_daily_trx = len(credit_period_df)\n",
    "                max_credit_daily_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "            if len(debit_period_df) > max_debit_daily_trx:\n",
    "                max_debit_daily_trx = len(debit_period_df)\n",
    "                max_debit_daily_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "        customer_stats.loc[customer, df_key+'_max_credit_daily_trx'] = max_credit_daily_trx\n",
    "        customer_stats.loc[customer, df_key+'_max_credit_daily_trx_avg_val'] = max_credit_daily_trx_avg_val\n",
    "        customer_stats.loc[customer, df_key+'_max_debit_daily_trx'] = max_debit_daily_trx\n",
    "        customer_stats.loc[customer, df_key+'_max_debit_daily_trx_avg_val'] = max_debit_daily_trx_avg_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]ter'>)>_single_df' on <module '__main__' (<class '_frozen_importlib.BuiltinImpor\n",
      "\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 93\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (df_key, customer_stats_p)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# dfs.items() produces (df_key, df) tuples.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/process.py:642\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "def process_single_df(item):\n",
    "    df_key, df = item\n",
    "    \n",
    "    df_customers = sorted(df['customer_id'].unique()) \n",
    "    customer_stats_p = pd.DataFrame(index=df_customers)\n",
    "    start_idx = 0\n",
    "    curr_idx = 0\n",
    "    last_idx = None\n",
    "        \n",
    "    for customer in tqdm(df_customers):\n",
    "        end_flag = False\n",
    "        while (df.loc[curr_idx, 'customer_id'] == customer):\n",
    "            # print(df.loc[curr_idx, 'customer_id'])\n",
    "            curr_idx += 1\n",
    "            # print(curr_idx)\n",
    "            if curr_idx == len(df):\n",
    "                end_flag = True\n",
    "                break\n",
    "        last_idx = curr_idx            \n",
    "        \n",
    "        if not end_flag:\n",
    "            customer_df = df.iloc[start_idx:last_idx, :]\n",
    "        else:\n",
    "            customer_df = df.iloc[start_idx:, :]\n",
    "\n",
    "        start_idx = curr_idx\n",
    "        \n",
    "        max_credit_minute_trx = 0 \n",
    "        max_credit_daily_trx = 0\n",
    "        # max_credit_weekly_trx = 0\n",
    "        # max_credit_monthly_trx = 0\n",
    "        max_credit_minute_trx_avg_val = 0\n",
    "        max_credit_daily_trx_avg_val = 0\n",
    "        # max_credit_weekly_trx_avg_val = 0\n",
    "        # max_credit_monthly_trx_avg_val = 0\n",
    "        \n",
    "        max_debit_minute_trx = 0\n",
    "        max_debit_daily_trx = 0\n",
    "        # max_debit_weekly_trx = 0\n",
    "        # max_debit_monthly_trx = 0\n",
    "        max_debit_minute_trx_avg_val = 0\n",
    "        max_debit_daily_trx_avg_val = 0\n",
    "        # max_debit_weekly_trx_avg_val = 0\n",
    "        # max_debit_monthly_trx_avg_val = 0\n",
    "                \n",
    "        start_date = df['transaction_datetime'].min()\n",
    "        end_date = df['transaction_datetime'].max()\n",
    "        # weekly_ranges, monthly_ranges = get_date_ranges(start_date, end_date)\n",
    "        minute_ranges, day_ranges = get_minute_day_ranges(start_date, end_date)\n",
    " \n",
    "        \n",
    "        for i, (start, end) in enumerate(minute_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            if len(credit_period_df) > max_credit_minute_trx:\n",
    "                max_credit_minute_trx = len(credit_period_df)\n",
    "                max_credit_minute_trx_avg_val = credit_period_df['amount_cad'].mean()    \n",
    "            if len(debit_period_df) > max_debit_minute_trx:\n",
    "                max_debit_minute_trx = len(debit_period_df)\n",
    "                max_debit_minute_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "        customer_stats_p.loc[customer, df_key+'_max_credit_minute_trx'] = max_credit_minute_trx\n",
    "        customer_stats_p.loc[customer, df_key+'_max_debit_minute_trx_avg_val'] = max_debit_minute_trx_avg_val\n",
    "        customer_stats_p.loc[customer, df_key+'_max_debit_minute_trx'] = max_debit_minute_trx\n",
    "        customer_stats_p.loc[customer, df_key+'_max_credit_minute_trx_avg_val'] = max_credit_minute_trx_avg_val\n",
    "        \n",
    "        for i, (start, end) in enumerate(day_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            if len(credit_period_df) > max_credit_daily_trx:\n",
    "                max_credit_daily_trx = len(credit_period_df)\n",
    "                max_credit_daily_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "            if len(debit_period_df) > max_debit_daily_trx:\n",
    "                max_debit_daily_trx = len(debit_period_df)\n",
    "                max_debit_daily_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "        customer_stats_p.loc[customer, df_key+'_max_credit_daily_trx'] = max_credit_daily_trx\n",
    "        customer_stats_p.loc[customer, df_key+'_max_credit_daily_trx_avg_val'] = max_credit_daily_trx_avg_val\n",
    "        customer_stats_p.loc[customer, df_key+'_max_debit_daily_trx'] = max_debit_daily_trx\n",
    "        customer_stats_p.loc[customer, df_key+'_max_debit_daily_trx_avg_val'] = max_debit_daily_trx_avg_val\n",
    "        \n",
    "    return (df_key, customer_stats_p)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    # dfs.items() produces (df_key, df) tuples.\n",
    "    results = list(tqdm(executor.map(process_single_df, dfs.items()), total=len(dfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 168/168 [00:11<00:00, 15.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.48it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:05<00:00, 15.00it/s]\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
      "/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_99936/2241701815.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:16<00:00, 14.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# Suppose customer_stats DataFrame is already created with customers as the index.\n",
    "# And dfs is a dictionary of DataFrames keyed by something (e.g., transaction type).\n",
    "\n",
    "for df_key in dfs.keys():\n",
    "    df = dfs[df_key]\n",
    "    df_customers = sorted(df['customer_id'].unique()) \n",
    "    \n",
    "    start_idx = 0\n",
    "    curr_idx = 0\n",
    "    last_idx = None\n",
    "        \n",
    "    for customer in tqdm(df_customers):\n",
    "        end_flag = False\n",
    "        while (df.loc[curr_idx, 'customer_id'] == customer):\n",
    "            curr_idx += 1\n",
    "            if curr_idx == len(df):\n",
    "                end_flag = True\n",
    "                break\n",
    "        last_idx = curr_idx            \n",
    "        \n",
    "        if not end_flag:\n",
    "            customer_df = df.iloc[start_idx:last_idx, :]\n",
    "        else:\n",
    "            customer_df = df.iloc[start_idx:, :]\n",
    "\n",
    "        start_idx = curr_idx\n",
    "        \n",
    "        # Prepare lists to hold (count, avg) tuples for top 5 metrics.\n",
    "        credit_minute_list = []\n",
    "        debit_minute_list = []\n",
    "        credit_daily_list = []\n",
    "        debit_daily_list = []\n",
    "                \n",
    "        start_date = df['transaction_datetime'].min()\n",
    "        end_date = df['transaction_datetime'].max()\n",
    "        minute_ranges, day_ranges = get_minute_day_ranges(start_date, end_date)\n",
    "        \n",
    "        # Process minute ranges\n",
    "        for (start, end) in minute_ranges:\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            # For credit\n",
    "            credit_count = len(credit_period_df)\n",
    "            credit_avg = credit_period_df['amount_cad'].mean() if credit_count > 0 else 0\n",
    "            credit_minute_list.append((credit_count, credit_avg))\n",
    "            \n",
    "            # For debit\n",
    "            debit_count = len(debit_period_df)\n",
    "            debit_avg = debit_period_df['amount_cad'].mean() if debit_count > 0 else 0\n",
    "            debit_minute_list.append((debit_count, debit_avg))\n",
    "        \n",
    "        # Process day ranges\n",
    "        for (start, end) in day_ranges:\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & (customer_df['transaction_datetime'] <= end)]\n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            credit_count = len(credit_period_df)\n",
    "            credit_avg = credit_period_df['amount_cad'].mean() if credit_count > 0 else 0\n",
    "            credit_daily_list.append((credit_count, credit_avg))\n",
    "            \n",
    "            debit_count = len(debit_period_df)\n",
    "            debit_avg = debit_period_df['amount_cad'].mean() if debit_count > 0 else 0\n",
    "            debit_daily_list.append((debit_count, debit_avg))\n",
    "        \n",
    "        # Sort and get top 5 for each category\n",
    "        top5_credit_minute = sorted(credit_minute_list, key=lambda x: x[0], reverse=True)[:2]\n",
    "        top5_debit_minute = sorted(debit_minute_list, key=lambda x: x[0], reverse=True)[:2]\n",
    "        top5_credit_daily = sorted(credit_daily_list, key=lambda x: x[0], reverse=True)[:2]\n",
    "        top5_debit_daily = sorted(debit_daily_list, key=lambda x: x[0], reverse=True)[:2]\n",
    "        \n",
    "        for i in range(2):\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_count'] = top5_credit_minute[i][0]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_minute_trx_avg_val'] = top5_credit_minute[i][1]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_count'] = top5_debit_minute[i][0]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_minute_trx_avg_val'] = top5_debit_minute[i][1]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_count'] = top5_credit_daily[i][0]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_credit_daily_trx_avg_val'] = top5_credit_daily[i][1]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_count'] = top5_debit_daily[i][0]\n",
    "            customer_stats.loc[customer, df_key+f'_top{str(i)}_debit_daily_trx_avg_val'] = top5_debit_daily[i][1]\n",
    "        \n",
    "        # # You can store these as lists in the DataFrame.\n",
    "        # customer_stats.loc[customer, df_key+'_top5_credit_minute'] = str(top5_credit_minute)\n",
    "        # customer_stats.loc[customer, df_key+'_top5_debit_minute'] = str(top5_debit_minute)\n",
    "        # customer_stats.loc[customer, df_key+'_top5_credit_daily'] = str(top5_credit_daily)\n",
    "        # customer_stats.loc[customer, df_key+'_top5_debit_daily'] = str(top5_debit_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/191927 [00:16<49:52:01,  1.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rv/m9l3_5yj5393fgp72c2hbr3w0000gn/T/ipykernel_73283/879164729.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mminute_ranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_minute_day_ranges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Process minute ranges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminute_ranges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             period_df = customer_df[(customer_df['transaction_datetime'] >= start) & \n\u001b[0m\u001b[1;32m     36\u001b[0m                                     \u001b[0;34m(\u001b[0m\u001b[0mcustomer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transaction_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcredit_period_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'debit_credit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'credit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdebit_period_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiod_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'debit_credit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'debit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4089\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4091\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m         \u001b[0;31m# We interpret tuples as collections only for non-MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4154\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for df_key in dfs.keys():\n",
    "    df = dfs[df_key]\n",
    "    df_customers = sorted(df['customer_id'].unique()) \n",
    "    \n",
    "    start_idx = 0\n",
    "    curr_idx = 0\n",
    "    last_idx = None\n",
    "        \n",
    "    for customer in tqdm(df_customers):\n",
    "        end_flag = False\n",
    "        while (df.loc[curr_idx, 'customer_id'] == customer):\n",
    "            curr_idx += 1\n",
    "            if curr_idx == len(df):\n",
    "                end_flag = True\n",
    "                break\n",
    "        last_idx = curr_idx            \n",
    "        \n",
    "        if not end_flag:\n",
    "            customer_df = df.iloc[start_idx:last_idx, :]\n",
    "        else:\n",
    "            customer_df = df.iloc[start_idx:, :]\n",
    "\n",
    "        start_idx = curr_idx\n",
    "        \n",
    "        # Prepare lists to collect (count, avg) tuples per period.\n",
    "        credit_minute_list = []\n",
    "        debit_minute_list = []\n",
    "                \n",
    "        start_date = df['transaction_datetime'].min()\n",
    "        end_date = df['transaction_datetime'].max()\n",
    "        minute_ranges, day_ranges = get_minute_day_ranges(start_date, end_date)\n",
    "        \n",
    "        # Process minute ranges\n",
    "        for (start, end) in minute_ranges:\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & \n",
    "                                    (customer_df['transaction_datetime'] <= end)]\n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            credit_count = len(credit_period_df)\n",
    "            credit_avg = credit_period_df['amount_cad'].mean() if credit_count > 0 else 0\n",
    "            credit_minute_list.append((credit_count, credit_avg))\n",
    "            \n",
    "            debit_count = len(debit_period_df)\n",
    "            debit_avg = debit_period_df['amount_cad'].mean() if debit_count > 0 else 0\n",
    "            debit_minute_list.append((debit_count, debit_avg))\n",
    "        \n",
    "        # Sort and pick top 5 (based on count) for credit and debit\n",
    "        top5_credit_minute = sorted(credit_minute_list, key=lambda x: x[0], reverse=True)[:5]\n",
    "        top5_debit_minute = sorted(debit_minute_list, key=lambda x: x[0], reverse=True)[:5]\n",
    "        \n",
    "        # Store the top 5 values in 5 different columns each.\n",
    "        for i in range(5):\n",
    "            if i < len(top5_credit_minute):\n",
    "                credit_count, credit_avg = top5_credit_minute[i]\n",
    "            else:\n",
    "                credit_count, credit_avg = None, None\n",
    "            if i < len(top5_debit_minute):\n",
    "                debit_count, debit_avg = top5_debit_minute[i]\n",
    "            else:\n",
    "                debit_count, debit_avg = None, None\n",
    "            \n",
    "            customer_stats.loc[customer, f'{df_key}_credit_minute_top{i+1}_count'] = credit_count\n",
    "            customer_stats.loc[customer, f'{df_key}_credit_minute_top{i+1}_avg'] = credit_avg\n",
    "            \n",
    "            customer_stats.loc[customer, f'{df_key}_debit_minute_top{i+1}_count'] = debit_count\n",
    "            customer_stats.loc[customer, f'{df_key}_debit_minute_top{i+1}_avg'] = debit_avg\n",
    "        \n",
    "        # Similarly, to do this for daily ranges, you can follow the same pattern:\n",
    "        credit_daily_list = []\n",
    "        debit_daily_list = []\n",
    "        for (start, end) in day_ranges:\n",
    "            period_df = customer_df[(customer_df['transaction_datetime'] >= start) & \n",
    "                                    (customer_df['transaction_datetime'] <= end)]\n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            credit_count = len(credit_period_df)\n",
    "            credit_avg = credit_period_df['amount_cad'].mean() if credit_count > 0 else 0\n",
    "            credit_daily_list.append((credit_count, credit_avg))\n",
    "            \n",
    "            debit_count = len(debit_period_df)\n",
    "            debit_avg = debit_period_df['amount_cad'].mean() if debit_count > 0 else 0\n",
    "            debit_daily_list.append((debit_count, debit_avg))\n",
    "        \n",
    "        top5_credit_daily = sorted(credit_daily_list, key=lambda x: x[0], reverse=True)[:5]\n",
    "        top5_debit_daily = sorted(debit_daily_list, key=lambda x: x[0], reverse=True)[:5]\n",
    "\n",
    "        for i in range(5):\n",
    "            if i < len(top5_credit_daily):\n",
    "                credit_count, credit_avg = top5_credit_daily[i]\n",
    "            else:\n",
    "                credit_count, credit_avg = None, None\n",
    "            if i < len(top5_debit_daily):\n",
    "                debit_count, debit_avg = top5_debit_daily[i]\n",
    "            else:\n",
    "                debit_count, debit_avg = None, None\n",
    "            \n",
    "            customer_stats.loc[customer, f'{df_key}_credit_daily_top{i+1}_count'] = credit_count\n",
    "            customer_stats.loc[customer, f'{df_key}_credit_daily_top{i+1}_avg'] = credit_avg\n",
    "            \n",
    "            customer_stats.loc[customer, f'{df_key}_debit_daily_top{i+1}_count'] = debit_count\n",
    "            customer_stats.loc[customer, f'{df_key}_debit_daily_top{i+1}_avg'] = debit_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_stats = pd.DataFrame({'customer_id': all_customers})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2240 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 750/2240 [00:16<00:32, 45.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m customer_stats\u001b[38;5;241m.\u001b[39mloc[customer_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_credit_weekely_trx_avg_val\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m max_credit_weekly_trx_avg_val\n\u001b[1;32m     62\u001b[0m customer_stats\u001b[38;5;241m.\u001b[39mloc[customer_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_debit_weekly_trx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m max_debit_weekly_trx\n\u001b[0;32m---> 63\u001b[0m customer_stats\u001b[38;5;241m.\u001b[39mloc[\u001b[43mcustomer_stats\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustomer_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcustomer\u001b[49m, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_debit_weekely_trx_avg_val\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m max_debit_weekly_trx_avg_val\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Doing the monthly calculations\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(start, end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(monthly_ranges):\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# df_customers = {'card': card_customers, 'wire': wire_customers, 'ach': ach_customers, 'cheque': cheque_customers}\n",
    "\n",
    "# for df_key in dfs.keys():\n",
    "#     df = dfs[df_key]\n",
    "#     df_customers = sorted(df['customer_id'].unique()) \n",
    "    \n",
    "#     start_idx = 0\n",
    "#     curr_idx = 0\n",
    "#     last_idx = None\n",
    "        \n",
    "#     for customer in tqdm(df_customers):\n",
    "        \n",
    "#         end_flag = False\n",
    "#         while (df.loc[curr_idx, 'customer_id'] == customer):\n",
    "#             # print(df.loc[curr_idx, 'customer_id'])\n",
    "#             curr_idx += 1\n",
    "#             # print(curr_idx)\n",
    "#             if curr_idx == len(df):\n",
    "#                 end_flag = True\n",
    "#                 break\n",
    "#         last_idx = curr_idx            \n",
    "        \n",
    "#         if not end_flag:\n",
    "#             customer_df = df.iloc[start_idx:last_idx, :]\n",
    "#         else:\n",
    "#             customer_df = df.iloc[start_idx:, :]\n",
    "#         l = l + len(customer_df)\n",
    "#         start_idx = curr_idx\n",
    "        \n",
    "#         max_credit_weekly_trx = 0\n",
    "#         max_credit_monthly_trx = 0\n",
    "#         max_credit_weekly_trx_avg_val = 0\n",
    "#         max_credit_monthly_trx_avg_val = 0\n",
    "        \n",
    "#         max_debit_weekly_trx = 0\n",
    "#         max_debit_monthly_trx = 0\n",
    "#         max_debit_weekly_trx_avg_val = 0\n",
    "#         max_debit_monthly_trx_avg_val = 0\n",
    "                \n",
    "#         start_date = df['transaction_date'].min()\n",
    "#         end_date = df['transaction_date'].max()\n",
    "#         weekly_ranges, monthly_ranges = get_date_ranges(start_date, end_date)\n",
    "        \n",
    "#         for i, (start, end) in enumerate(weekly_ranges):\n",
    "#             period_df = customer_df[(customer_df['transaction_date'] >= pd.to_datetime(start).date()) & (customer_df['transaction_date'] <= pd.to_datetime(end).date())]\n",
    "            \n",
    "#             credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "#             debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "#             if len(credit_period_df) > max_credit_weekly_trx:\n",
    "#                 max_credit_weekly_trx = len(credit_period_df)\n",
    "#                 max_credit_weekly_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "#             if len(debit_period_df) > max_debit_weekly_trx:\n",
    "#                 max_debit_weekly_trx = len(debit_period_df)\n",
    "#                 max_debit_weekly_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekly_trx'] = max_credit_weekly_trx\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekely_trx_avg_val'] = max_credit_weekly_trx_avg_val\n",
    "        \n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekly_trx'] = max_debit_weekly_trx\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekely_trx_avg_val'] = max_debit_weekly_trx_avg_val\n",
    "    \n",
    "        \n",
    "#         # Doing the monthly calculations\n",
    "#         for i,(start, end) in enumerate(monthly_ranges):\n",
    "#             period_df = customer_df[(customer_df['transaction_date'] >= pd.to_datetime(start).date()) & (customer_df['transaction_date'] <= pd.to_datetime(end).date())]\n",
    "            \n",
    "#             credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "#             debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "#             # Calculate the maximum number of transactions in a month and the average transaction value\n",
    "#             if len(credit_period_df) > max_credit_monthly_trx:\n",
    "#                 max_credit_monthly_trx = len(credit_period_df)\n",
    "#                 max_credit_monthly_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "#             if len(debit_period_df) > max_debit_monthly_trx:\n",
    "#                 max_debit_monthly_trx = len(debit_period_df)\n",
    "#                 max_debit_monthly_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "            \n",
    "#             # if len(period_df) > max_monthly_trx:\n",
    "#             #     max_monthly_trx = len(period_df)\n",
    "#             #     max_monthly_trx_avg_val = period_df['amount_cad'].mean()\n",
    "\n",
    "        \n",
    "#         # Store the maximum number of transactions and average transaction value for the month       \n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx'] = max_credit_monthly_trx\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx_avg_val'] = max_credit_monthly_trx_avg_val\n",
    "\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx'] = max_debit_monthly_trx\n",
    "#         customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx_avg_val'] = max_debit_monthly_trx_avg_val\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530870\n"
     ]
    }
   ],
   "source": [
    "ll = 0\n",
    "for df_key in dfs.keys():\n",
    "    ll = ll + len(dfs[df_key])\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/214958 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "  0%|          | 0/214958 [00:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m customer \u001b[38;5;129;01min\u001b[39;00m tqdm(all_customers):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Find the eariest and latest transaction date for the customer in this transaction type\u001b[39;00m\n\u001b[1;32m     12\u001b[0m    \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m    \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Setting the features to 0 if the customer is not present in the transactions       \u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m customer \u001b[38;5;241m!=\u001b[39m df_customers[df_key][start_idx]:\n\u001b[0;32m---> 18\u001b[0m         customer_stats\u001b[38;5;241m.\u001b[39mloc[customer_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_credit_weekly_trx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     19\u001b[0m         customer_stats\u001b[38;5;241m.\u001b[39mloc[customer_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_credit_monthly_trx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m         customer_stats\u001b[38;5;241m.\u001b[39mloc[customer_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer, df_key\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_max_credit_weekely_trx_avg_val\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1465\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._line_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1507\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1308\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1945\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/BigDeepStrongData/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_customers = {'wire': wire_customers, 'ach': ach_customers, 'cheque': cheque_customers, 'card': card_customers}\n",
    "all_customers = sorted(all_customers)\n",
    "for df_key in dfs.keys():\n",
    "    df = dfs[df_key]\n",
    "    \n",
    "    start_idx = 0\n",
    "    curr_idx = 0\n",
    "    last_idx = None\n",
    "        \n",
    "    for customer in tqdm(all_customers):\n",
    "        # Find the eariest and latest transaction date for the customer in this transaction type\n",
    "       \n",
    "        # if customer == 'SYNCID0000006876':\n",
    "        #     print(\"SYNCID0000006876\")\n",
    "       \n",
    "        # Setting the features to 0 if the customer is not present in the transactions       \n",
    "        if customer != df_customers[df_key][start_idx]:\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekly_trx'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekely_trx_avg_val'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx_avg_val'] = 0\n",
    "            \n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekly_trx'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekely_trx_avg_val'] = 0\n",
    "            customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx_avg_val'] = 0\n",
    "            continue\n",
    "        \n",
    "        # cust_df = pd.DataFrame()\n",
    "        end_flag = False\n",
    "        while df.loc[curr_idx, 'customer_id'] == customer:\n",
    "            curr_idx += 1\n",
    "            if curr_idx == len(df):\n",
    "                end_flag = True\n",
    "        last_idx = curr_idx \n",
    "        \n",
    "        if not end_flag:\n",
    "            customer_df = df.iloc[start_idx:last_idx, :]\n",
    "        else:\n",
    "            customer_df = df.iloc[start_idx:, :]\n",
    "            \n",
    "        start_idx = curr_idx\n",
    "            \n",
    "        \n",
    "        max_credit_weekly_trx = 0\n",
    "        max_credit_monthly_trx = 0\n",
    "        max_credit_weekly_trx_avg_val = 0\n",
    "        max_credit_monthly_trx_avg_val = 0\n",
    "        \n",
    "        max_debit_weekly_trx = 0\n",
    "        max_debit_monthly_trx = 0\n",
    "        max_debit_weekly_trx_avg_val = 0\n",
    "        max_debit_monthly_trx_avg_val = 0\n",
    "                \n",
    "        start_date = df['transaction_date'].min()\n",
    "        end_date = df['transaction_date'].max()\n",
    "        weekly_ranges, monthly_ranges = get_date_ranges(start_date, end_date)\n",
    "        \n",
    "        for i, (start, end) in enumerate(weekly_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_date'] >= pd.to_datetime(start).date()) & (customer_df['transaction_date'] <= pd.to_datetime(end).date())]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            if len(credit_period_df) > max_credit_weekly_trx:\n",
    "                max_credit_weekly_trx = len(credit_period_df)\n",
    "                max_credit_weekly_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "            if len(debit_period_df) > max_debit_weekly_trx:\n",
    "                max_debit_weekly_trx = len(debit_period_df)\n",
    "                max_debit_weekly_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekly_trx'] = max_credit_weekly_trx\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_weekely_trx_avg_val'] = max_credit_weekly_trx_avg_val\n",
    "        \n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekly_trx'] = max_debit_weekly_trx\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_weekely_trx_avg_val'] = max_debit_weekly_trx_avg_val\n",
    "    \n",
    "        \n",
    "        # Doing the monthly calculations\n",
    "        for i,(start, end) in enumerate(monthly_ranges):\n",
    "            period_df = customer_df[(customer_df['transaction_date'] >= pd.to_datetime(start).date()) & (customer_df['transaction_date'] <= pd.to_datetime(end).date())]\n",
    "            \n",
    "            credit_period_df = period_df[period_df['debit_credit'] == 'credit']\n",
    "            debit_period_df = period_df[period_df['debit_credit'] == 'debit']\n",
    "            \n",
    "            # Calculate the maximum number of transactions in a month and the average transaction value\n",
    "            if len(credit_period_df) > max_credit_monthly_trx:\n",
    "                max_credit_monthly_trx = len(credit_period_df)\n",
    "                max_credit_monthly_trx_avg_val = credit_period_df['amount_cad'].mean()\n",
    "            \n",
    "            if len(debit_period_df) > max_debit_monthly_trx:\n",
    "                max_debit_monthly_trx = len(debit_period_df)\n",
    "                max_debit_monthly_trx_avg_val = debit_period_df['amount_cad'].mean()\n",
    "\n",
    "        \n",
    "        # Store the maximum number of transactions and average transaction value for the month       \n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx'] = max_credit_monthly_trx\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_credit_monthly_trx_avg_val'] = max_credit_monthly_trx_avg_val\n",
    "\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx'] = max_debit_monthly_trx\n",
    "        customer_stats.loc[customer_stats['customer_id'] == customer, df_key+'_max_debit_monthly_trx_avg_val'] = max_debit_monthly_trx_avg_val\n",
    "        \n",
    "#save the customer stats to a csv file\n",
    "customer_stats.to_csv('../../processed_synth_dataset/features_4_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_stats = pd.read_csv('../../processed_synth_dataset/features_4_5.csv', engine=\"pyarrow\").sample(frac = frac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
